{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLwmFZfKxLi4"
   },
   "source": [
    "### CORPUS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corpus\n",
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLwmFZfKxLi4"
   },
   "source": [
    "### SkLearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(corpus)\n",
    "skl_output = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "  (0, 8)\t0.38408524091481483\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 1)\t0.46979138557992045\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())\n",
    "skl_output.shape\n",
    "print(skl_output[0])\n",
    "print(skl_output[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfIwx5LzxLjI"
   },
   "source": [
    "###  custom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "The class is a custom implementation of TFIDF Vectorizer. It is a basic tfidf vectorizer which requires a clean corpus as input where corpus is a list of strings.\n",
    "The transform() function returns a sparse normalized matrix.\n",
    "'''\n",
    "class cust_tfidf_vectorizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def featurize(self,text):\n",
    "        data=[j  for i in text for j in i]\n",
    "        vect=sorted(list(set(data)))\n",
    "        return vect\n",
    "    \n",
    "    def getfeatures(self):\n",
    "        return vector\n",
    "    \n",
    "    def get_idf(self):\n",
    "        return idf\n",
    "    \n",
    "    def term_freq(self,final,inpt,vector):\n",
    "        for i in range(len(inpt)):\n",
    "            for j in range(len(inpt[i])):\n",
    "                inpt[i][j]=final[i][vector[j]]/len(final[i])\n",
    "        return inpt\n",
    "    \n",
    "    def inverse_doc_freq(self,vector,final,text):\n",
    "        idf=[]\n",
    "        for i in vector:\n",
    "            c=0\n",
    "            for j in range(len(final)):\n",
    "                    if final[j][i]>0.:\n",
    "                        c=c+1\n",
    "            x=1+math.log((1+len(text))/(1+c))\n",
    "            idf.append(x)\n",
    "        idf=np.array(idf)\n",
    "        return idf\n",
    "\n",
    "    def fit(self,corpus):\n",
    "        '''\n",
    "        The function fits on the corpus to compute tf, idf and build vocabulary for the corpus.\n",
    "        '''\n",
    "        text=[i.split() for i in corpus]\n",
    "        final=[Counter(i) for i in text]\n",
    "        global vector,tf,idf\n",
    "        vector=self.featurize(text)\n",
    "        inpt=csr_matrix((len(text), len(vector))).toarray()\n",
    "        tf=self.term_freq(final,inpt,vector)\n",
    "        idf=self.inverse_doc_freq(vector,final,text)\n",
    "    \n",
    "    \n",
    "    def transform(self,corpus):\n",
    "        '''\n",
    "        The function returns a sparse normalized matrix thereby transforming a given corpus into a mtrix of tfidf vectors\n",
    "        '''\n",
    "        self.fit(corpus)\n",
    "        tfidf=[]\n",
    "        for i in tf:\n",
    "            a=np.multiply(i,idf)\n",
    "            tfidf.append(a)\n",
    "        tfidf=np.array(tfidf)\n",
    "        tfidf_new=normalize(tfidf,norm='l2')\n",
    "        tfidf=csr_matrix(tfidf_new)\n",
    "        return tfidf\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique features are: ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "The IDF vector is:  [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "The shape of output sparse matrix:  (4, 9)\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "The first element/document after transformation:\n",
      "  (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "#Implementation of above class on 1st corpus\n",
    "v=cust_tfidf_vectorizer()\n",
    "v.fit(corpus)\n",
    "print('The unique features are:',v.getfeatures())\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('The IDF vector is: ',v.get_idf())\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "o=v.transform(corpus)\n",
    "print('The shape of output sparse matrix: ',o.shape)\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('The first element/document after transformation:')\n",
    "print(o[0])\n",
    "print(o[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORPUS- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus =  746\n"
     ]
    }
   ],
   "source": [
    "# Below is the code to load the cleaned_strings pickle file provided\n",
    "# Here corpus is of list type\n",
    "\n",
    "import pickle\n",
    "with open('cleaned_strings', 'rb') as f:\n",
    "    corpus = pickle.load(f)\n",
    "    \n",
    "# printing the length of the corpus loaded\n",
    "print(\"Number of documents in corpus = \",len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "The class is a custom implementation of TFIDF Vectorizer with a limit on maximum number of features. \n",
    "It uses a clean corpus as input where corpus is a list of strings. The vectorizer limits the number of features to a given value. \n",
    "It is mandatory to pass a number to the class while initializing or else the code would give error. This number of features should be less than max number of unique features.\n",
    "Here, The function computes the top n features based on IDF values unlike sklearn where features are ranked based on their TF values.\n",
    "The tfidf vectors are generated for each document using these top n features, such that each vector has n columns representing n features.\n",
    "The transform() function returns a sparse normalized matrix with a shape of (len(no of documents), number_of_features(as given during initialising))\n",
    "'''\n",
    "\n",
    "class cust_tfidf_vectorizer:\n",
    "    def __init__(self,no_ft):\n",
    "        self.no_ft=no_ft\n",
    "    \n",
    "    def featurize(self,text):\n",
    "        data=[j  for i in text for j in i]\n",
    "        vect=sorted(list(set(data)))\n",
    "        return vect\n",
    "    \n",
    "    def getfeatures(self):\n",
    "        return vector\n",
    "    \n",
    "    def get_idf(self):\n",
    "        return idf\n",
    "    \n",
    "    def get_topfeatures(self):\n",
    "        return frame\n",
    "    \n",
    "    def term_freq(self,final,inpt,vector):\n",
    "        for i in range(len(inpt)):\n",
    "            for j in range(len(inpt[i])):\n",
    "                inpt[i][j]=final[i][vector[j]]/len(final[i])\n",
    "        return inpt\n",
    "    \n",
    "    def inverse_doc_freq(self,vector,final,text):\n",
    "        idf=[]\n",
    "        for i in vector:\n",
    "            c=0\n",
    "            for j in range(len(final)):\n",
    "                    if final[j][i]>0.:\n",
    "                        c=c+1\n",
    "            x=1+math.log((1+len(text))/(1+c))\n",
    "            idf.append(x)\n",
    "        idf=np.array(idf)\n",
    "        return idf\n",
    "\n",
    "    def fit(self,corpus):\n",
    "        '''\n",
    "        The function fits on the corpus to compute tf, idf and build vocabulary for the corpus.\n",
    "        '''\n",
    "        text=[i.split() for i in corpus]\n",
    "        final=[Counter(i) for i in text]\n",
    "        global vector,tf,idf,frame\n",
    "        vector=self.featurize(text)\n",
    "        idf=self.inverse_doc_freq(vector,final,text)\n",
    "        frame=list(zip(vector,idf))\n",
    "        frame.sort(key=operator.itemgetter(1),reverse=True)      # https://stackoverflow.com/questions/14466068/sort-a-list-of-tuples-by-second-value-reverse-true-and-then-by-key-reverse-fal\n",
    "        frame=[frame[i] for i in range(self.no_ft)]\n",
    "        vector=[frame[i][0] for i in range(self.no_ft)]\n",
    "        idf=[frame[i][1] for i in range(self.no_ft)]\n",
    "        inpt=csr_matrix((len(text), len(vector))).toarray()\n",
    "        tf=self.term_freq(final,inpt,vector)\n",
    "    \n",
    "    def transform(self,corpus):\n",
    "        '''\n",
    "        The function returns a sparse normalized matrix thereby transforming a given corpus into a mtrix of tfidf vectors\n",
    "        '''\n",
    "        self.fit(corpus)\n",
    "        tfidf=[]\n",
    "        for i in tf:\n",
    "            a=np.multiply(i,idf)\n",
    "            tfidf.append(a)\n",
    "        tfidf=np.array(tfidf)\n",
    "        tfidf_new=normalize(tfidf,norm='l2')\n",
    "        tfidf=csr_matrix(tfidf_new)\n",
    "        return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 features based on their IDF values: \n",
      "['aailiyah', 'abandoned', 'abroad', 'abstruse', 'academy', 'accents', 'accessible', 'acclaimed', 'accolades', 'accurate', 'accurately', 'achille', 'ackerman', 'actions', 'adams', 'add', 'added', 'admins', 'admiration', 'admitted', 'adrift', 'adventure', 'aesthetically', 'affected', 'affleck', 'afternoon', 'aged', 'ages', 'agree', 'agreed', 'aimless', 'aired', 'akasha', 'akin', 'alert', 'alike', 'allison', 'allow', 'allowing', 'alongside', 'amateurish', 'amaze', 'amazed', 'amazingly', 'amusing', 'amust', 'anatomist', 'angel', 'angela', 'angelina']\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "IDF values of top 50 features:\n",
      "[6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872, 6.922918004572872]\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Top features alongwith their IDF values:\n",
      "[('aailiyah', 6.922918004572872), ('abandoned', 6.922918004572872), ('abroad', 6.922918004572872), ('abstruse', 6.922918004572872), ('academy', 6.922918004572872), ('accents', 6.922918004572872), ('accessible', 6.922918004572872), ('acclaimed', 6.922918004572872), ('accolades', 6.922918004572872), ('accurate', 6.922918004572872), ('accurately', 6.922918004572872), ('achille', 6.922918004572872), ('ackerman', 6.922918004572872), ('actions', 6.922918004572872), ('adams', 6.922918004572872), ('add', 6.922918004572872), ('added', 6.922918004572872), ('admins', 6.922918004572872), ('admiration', 6.922918004572872), ('admitted', 6.922918004572872), ('adrift', 6.922918004572872), ('adventure', 6.922918004572872), ('aesthetically', 6.922918004572872), ('affected', 6.922918004572872), ('affleck', 6.922918004572872), ('afternoon', 6.922918004572872), ('aged', 6.922918004572872), ('ages', 6.922918004572872), ('agree', 6.922918004572872), ('agreed', 6.922918004572872), ('aimless', 6.922918004572872), ('aired', 6.922918004572872), ('akasha', 6.922918004572872), ('akin', 6.922918004572872), ('alert', 6.922918004572872), ('alike', 6.922918004572872), ('allison', 6.922918004572872), ('allow', 6.922918004572872), ('allowing', 6.922918004572872), ('alongside', 6.922918004572872), ('amateurish', 6.922918004572872), ('amaze', 6.922918004572872), ('amazed', 6.922918004572872), ('amazingly', 6.922918004572872), ('amusing', 6.922918004572872), ('amust', 6.922918004572872), ('anatomist', 6.922918004572872), ('angel', 6.922918004572872), ('angela', 6.922918004572872), ('angelina', 6.922918004572872)]\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Shape of output matrix: (746, 50)\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "One document of corpus after transformation:\n",
      "  (0, 3)\t0.37796447300922725\n",
      "  (0, 10)\t0.37796447300922725\n",
      "  (0, 18)\t0.37796447300922725\n",
      "  (0, 20)\t0.37796447300922725\n",
      "  (0, 36)\t0.37796447300922725\n",
      "  (0, 40)\t0.37796447300922725\n",
      "  (0, 41)\t0.37796447300922725\n",
      "[[0.         0.         0.         0.37796447 0.         0.\n",
      "  0.         0.         0.         0.         0.37796447 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37796447 0.         0.37796447 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.37796447 0.         0.         0.         0.37796447 0.37796447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Implementation of above class for n=50\n",
    "v=cust_tfidf_vectorizer(50)\n",
    "v.fit(corpus)\n",
    "print('Top 50 features based on their IDF values: ')\n",
    "print(v.getfeatures())\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('IDF values of top 50 features:')\n",
    "print(v.get_idf())\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('Top features alongwith their IDF values:')\n",
    "print(v.get_topfeatures())\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "o=v.transform(corpus)\n",
    "print('Shape of output matrix:',o.shape)\n",
    "print('---------------------------------------------------------------------------------------------------------------------------')\n",
    "print('One document of corpus after transformation:')\n",
    "print(o[135])\n",
    "print(o[135].toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
